<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>networkedwebsitesdetector • networkedwebsitesdetector</title>
<!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js" integrity="sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8=" crossorigin="anonymous"></script><!-- Bootstrap --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha256-916EbMg70RQy9LHiGkXzG8hSg9EdNy97GazNG/aiY1w=" crossorigin="anonymous">
<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha256-U5ZEeKfGNOja007MMD3YBI0A3OSZOQbeG6z2f2Y0hu8=" crossorigin="anonymous"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" integrity="sha256-eZrrJcwDc/3uDhsdt61sL2oOBY362qM3lon1gyExkL0=" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.4/clipboard.min.js" integrity="sha256-FiZwavyI2V6+EXO1U+xzLG3IKldpiTFf3153ea9zikQ=" crossorigin="anonymous"></script><!-- sticky kit --><script src="https://cdnjs.cloudflare.com/ajax/libs/sticky-kit/1.1.3/sticky-kit.min.js" integrity="sha256-c4Rlo1ZozqTPE2RLuvbusY3+SU1pQaJC0TjuhygMipw=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script><meta property="og:title" content="networkedwebsitesdetector">
<meta property="og:description" content="">
<meta name="twitter:card" content="summary">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <div class="container template-article">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">networkedwebsitesdetector</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="Released version">0.0.1.9000</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../index.html">
    <span class="fa fa-home fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="../articles/networkedwebsitesdetector.html">Get started</a>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../articles/backup_restore.html">Backup and restore files</a>
    </li>
    <li>
      <a href="../articles/identifiers_excluded_by_default.html">Identifiers excluded by default</a>
    </li>
  </ul>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right">
<li>
  <a href="https://github.com/giocomai/networkedwebsitesdetector">
    <span class="fa fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      
      </header><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header toc-ignore">
      <h1>networkedwebsitesdetector</h1>
            
      
      <small class="dont-index">Source: <a href="https://github.com/giocomai/networkedwebsitesdetector/blob/master/vignettes/networkedwebsitesdetector.Rmd"><code>vignettes/networkedwebsitesdetector.Rmd</code></a></small>
      <div class="hidden name"><code>networkedwebsitesdetector.Rmd</code></div>

    </div>

    
    
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1-1" data-line-number="1"><span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/library">library</a></span>(networkedwebsitesdetector)</a></code></pre></div>
<div id="getting-websites" class="section level1">
<h1 class="hasAnchor">
<a href="#getting-websites" class="anchor"></a>Getting websites</h1>
<p>In order to find networks of websites, we need to have a list of websites. If you have it, you can skip to the “Download homepages” section. Otherwise, here’s an approach to finding a list of websites, including (but not limited to) websites which talk about current events.</p>
<p>This approach is based on getting news headlines in a given language, finding the words that appear most often in the news in a given day, then look for them on Twitter, and extract domain names from links inlcuded in those tweets. This package includes a number of helper functions to streamline the process.</p>
<p>It is a very opinionated package, and will by default create folders, store things locally, and in ensuing steps process what is available, without demanding detailed paramater inputs from the user. The whole package is built assuming that the user will want to find networks of websites using a given language, but it makes it easy to replicate the same approach across languages.</p>
<p>The package includes a number of helper functions to compress, archive, and remotely back-up data on Google Drive. They will be presented in a separate vignette.</p>
<p>The whole process can be consistently repeated from a server. Details on how to set up a Docker image doing all the steps will also be presented in a separate vignette.</p>
<div id="getting-the-news" class="section level2">
<h2 class="hasAnchor">
<a href="#getting-the-news" class="anchor"></a>Getting the news</h2>
<p><code>nwd_get_emm_newsbrief</code> gets the current rss feed from a news aggregator, <a href="http://emm.newsbrief.eu/">EMM newsbrief</a>, and stores them in a local sub-folder according to a pre-defined scheme.</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb2-1" data-line-number="1"><span class="kw"><a href="../reference/nwd_get_emm_newsbrief.html">nwd_get_emm_newsbrief</a></span>(<span class="dt">languages =</span> <span class="st">"it"</span>)</a></code></pre></div>
<p>Timestamped files are stored in a subfolders by date, as follows, by default both in the original xml format and in a pre-processed data frame to be used more easily in R.</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb3-1" data-line-number="1">fs<span class="op">::</span><span class="kw"><a href="http://fs.r-lib.org/reference/dir_tree.html">dir_tree</a></span>(<span class="dt">path =</span> <span class="st">"emm_newsbrief"</span>)</a></code></pre></div>
<p>Having downloaded some news, it is possible to extract what were the most frequent keywords over a given period, such as a given date. Again, an helper function will remove relevant stopwords and output the words most frequently used over a given day, and store resulting data locally.</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb4-1" data-line-number="1"><span class="kw"><a href="../reference/nwd_extract_keywords.html">nwd_extract_keywords</a></span>()</a></code></pre></div>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb5-1" data-line-number="1">fs<span class="op">::</span><span class="kw"><a href="http://fs.r-lib.org/reference/dir_tree.html">dir_tree</a></span>(<span class="dt">path =</span> <span class="st">"keywords"</span>)</a></code></pre></div>
</div>
<div id="getting-inputs-from-twitter" class="section level2">
<h2 class="hasAnchor">
<a href="#getting-inputs-from-twitter" class="anchor"></a>Getting inputs from Twitter</h2>
<p>Once keywords are extracted, it is possible to look for them on Twitter. This assumes a valid Twitter token is part of the environment, as <a href="https://rtweet.info/articles/auth.html">detailed here</a>.</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb6-1" data-line-number="1"><span class="kw"><a href="../reference/nwd_get_tweets.html">nwd_get_tweets</a></span>()</a></code></pre></div>
<p>Name of files include details about the exact query made to the Twitter api: first the term, then the language filter, then the number of tweets requested, the type of tweets requested (can be “recent”, “mixed”, or “popular”), and the exact timing of the request.</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb7-1" data-line-number="1">fs<span class="op">::</span><span class="kw"><a href="http://fs.r-lib.org/reference/dir_tree.html">dir_tree</a></span>(<span class="dt">path =</span> <span class="st">"tweets"</span>)</a></code></pre></div>
</div>
<div id="extracting-links-and-domains" class="section level2">
<h2 class="hasAnchor">
<a href="#extracting-links-and-domains" class="anchor"></a>Extracting links and domains</h2>
<p>Now, it’s time to get links out of tweets. URLs shortened not only by Twitter, but also by third parties such as bit.ly, are expanded by default. Expanding URLs can be time consuming, so keep this in mind as you plan activities.</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb8-1" data-line-number="1"></a>
<a class="sourceLine" id="cb8-2" data-line-number="2"><span class="kw"><a href="../reference/nwd_extract_urls_from_tweets.html">nwd_extract_urls_from_tweets</a></span>()</a>
<a class="sourceLine" id="cb8-3" data-line-number="3">    </a></code></pre></div>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb9-1" data-line-number="1">fs<span class="op">::</span><span class="kw"><a href="http://fs.r-lib.org/reference/dir_tree.html">dir_tree</a></span>(<span class="dt">path =</span> <span class="st">"tweet_links"</span>)</a></code></pre></div>
<p>It would now be possible to download links, or at least the most common among them, as the number of unique links grows very quickly. As a first step, it may however make sense to extract only the homepage for each of the links found so far.</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb10-1" data-line-number="1"><span class="kw"><a href="../reference/nwd_extract_domains.html">nwd_extract_domains</a></span>()</a></code></pre></div>
</div>
</div>
<div id="download-homepages" class="section level1">
<h1 class="hasAnchor">
<a href="#download-homepages" class="anchor"></a>Download homepages</h1>
<p>Based on the domain names extracted from links included in tweets as details above, it is now possible to download home pages. Of course, if you already have a list of domains you wish to download, you can skip all previous steps and start with <code><a href="../reference/nwd_get_homepage.html">nwd_get_homepage()</a></code>.</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb11-1" data-line-number="1">domains &lt;-<span class="st"> </span>purrr<span class="op">::</span><span class="kw"><a href="https://purrr.tidyverse.org/reference/map.html">map_dfr</a></span>(<span class="dt">.x =</span> fs<span class="op">::</span><span class="kw"><a href="http://fs.r-lib.org/reference/dir_ls.html">dir_ls</a></span>(<span class="dt">path =</span> fs<span class="op">::</span><span class="kw"><a href="http://fs.r-lib.org/reference/path.html">path</a></span>(<span class="st">"domains"</span>, <span class="st">"it"</span>)), <span class="dt">.f =</span> readRDS)</a>
<a class="sourceLine" id="cb11-2" data-line-number="2"></a>
<a class="sourceLine" id="cb11-3" data-line-number="3"><span class="kw"><a href="../reference/nwd_get_homepage.html">nwd_get_homepage</a></span>(<span class="dt">domain =</span> <span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/unique">unique</a></span>(domains<span class="op">$</span>domain), <span class="dt">language =</span> <span class="st">"it"</span>)</a></code></pre></div>
<p><code><a href="../reference/nwd_get_homepage.html">nwd_get_homepage()</a></code> downloads homepages in html format in a dedicated, dated subfolder. By default, it does not download again a file if has been already downloaded in the last three months. This can be customised by setting the <code>since</code> parameter, e.g. <code><a href="../reference/nwd_get_homepage.html">nwd_get_homepage(domain = unique(domains$domain), language = "it", since = Sys.Date()-31)</a></code>.</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb12-1" data-line-number="1"><span class="kw"><a href="../reference/nwd_clean_files.html">nwd_clean_files</a></span>(<span class="dt">remove_exceeding =</span> <span class="ot">TRUE</span>)</a></code></pre></div>
</div>
<div id="extract-identifiers" class="section level1">
<h1 class="hasAnchor">
<a href="#extract-identifiers" class="anchor"></a>Extract identifiers</h1>
<p>The following function will extract identifiers such as Google Analytics and Google Adwords id, and store them in a dated folder.</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb13-1" data-line-number="1"><span class="kw"><a href="../reference/nwd_extract_identifiers.html">nwd_extract_identifiers</a></span>()</a></code></pre></div>
</div>
<div id="find-networks" class="section level1">
<h1 class="hasAnchor">
<a href="#find-networks" class="anchor"></a>Find networks</h1>
<p>Once identifiers have been extracted, it is finally possible to find networks. A table in the long format including all identifiers can be retrieved with the following command:</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb14-1" data-line-number="1"><span class="kw"><a href="../reference/nwd_load_identifiers_df.html">nwd_load_identifiers_df</a></span>()</a></code></pre></div>
<p>If you wish to include an additional column showing which networks share the same id, there is a dedicated function for that:</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb15-1" data-line-number="1"><span class="kw"><a href="../reference/nwd_add_network_id.html">nwd_add_network_id</a></span>()</a></code></pre></div>
<p>Both of these by default store the output in a dedicated subfolder, in order to limit re-processing of the same data, as these are steps that can easily take hours of computing time.</p>
<p>If you wish to find out about the network of a specific domain, you can use the following command:</p>
<div class="sourceCode" id="cb16"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb16-1" data-line-number="1"><span class="kw">nwd_find_related_domains</span>()</a></code></pre></div>
<p>If youy prefer a visual output, this command will create the relevant graph:</p>
<div class="sourceCode" id="cb17"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb17-1" data-line-number="1"><span class="kw">nwd_create_domain_graph_identifiers</span>()</a></code></pre></div>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="sidebar">
        <div id="tocnav">
      <h2 class="hasAnchor">
<a href="#tocnav" class="anchor"></a>Contents</h2>
      <ul class="nav nav-pills nav-stacked">
<li>
<a href="#getting-websites">Getting websites</a><ul class="nav nav-pills nav-stacked">
<li><a href="#getting-the-news">Getting the news</a></li>
      <li><a href="#getting-inputs-from-twitter">Getting inputs from Twitter</a></li>
      <li><a href="#extracting-links-and-domains">Extracting links and domains</a></li>
      </ul>
</li>
      <li><a href="#download-homepages">Download homepages</a></li>
      <li><a href="#extract-identifiers">Extract identifiers</a></li>
      <li><a href="#find-networks">Find networks</a></li>
      </ul>
</div>
      </div>

</div>


      <footer><div class="copyright">
  <p>Developed by Giorgio Comai.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="https://pkgdown.r-lib.org/">pkgdown</a> 1.3.0.</p>
</div>
      </footer>
</div>

  

  </body>
</html>
